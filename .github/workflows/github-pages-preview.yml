---
name: GitHub Pages preview
on:
  workflow_dispatch:
    inputs:
      branch:
        description: "Branch to deploy"
        type: string
        required: false
        default: ""
  # For testing: runs on push to any branch containing 'preview' or 'gh-pages'
  # Remove this trigger after testing is complete
  push:
    branches:
      - "**/preview**"
      - "**/gh-pages**"
      - "preview-**"
      - "gh-pages-**"

# Sets permissions of the GITHUB_TOKEN to allow deployment to GitHub Pages
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment, skipping runs queued between the run in-progress and latest queued.
# However, do NOT cancel in-progress runs as we want to allow these production deployments to complete.
concurrency:
  group: pages
  cancel-in-progress: false

jobs:
  build:
    name: Build
    runs-on: ubuntu-latest
    steps:
      - name: Checkout content repo
        uses: actions/checkout@v4
        with:
          ref: ${{ inputs.branch || github.ref }}
          path: content

      - name: Clone adp-devsite
        uses: actions/checkout@v4
        with:
          repository: AdobeDocs/adp-devsite
          path: adp-devsite

      - name: Clone devsite-runtime-connector
        uses: actions/checkout@v4
        with:
          repository: aemsites/devsite-runtime-connector
          path: devsite-runtime-connector

      - name: Setup Node.js
        uses: actions/setup-node@v4
        with:
          node-version: "lts/jod"

      - name: Install dependencies
        run: |
          cd content && npm install && cd ..
          cd adp-devsite && npm install && cd ..
          cd devsite-runtime-connector && npm install

      - name: Start servers and generate static site
        run: |
          set -x  # Enable debug output
          ROOT_DIR=$(pwd)

          # Start content server (port 3003)
          echo "Starting content server..."
          (cd "$ROOT_DIR/content" && npm run dev 2>&1 | tee "$ROOT_DIR/content-server.log") &
          CONTENT_PID=$!

          # Start adp-devsite (port 3000)
          echo "Starting adp-devsite..."
          (cd "$ROOT_DIR/adp-devsite" && npm run dev 2>&1 | tee "$ROOT_DIR/devsite-server.log") &
          DEVSITE_PID=$!

          # Start runtime connector
          echo "Starting runtime connector..."
          (cd "$ROOT_DIR/devsite-runtime-connector" && npm run dev 2>&1 | tee "$ROOT_DIR/connector-server.log") &
          CONNECTOR_PID=$!

          # Wait for servers to be ready
          echo "Waiting for servers to start..."
          sleep 20

          # Debug: Show server logs
          echo "=== Content server log ==="
          cat "$ROOT_DIR/content-server.log" | tail -50 || true
          echo "=== Devsite server log ==="
          cat "$ROOT_DIR/devsite-server.log" | tail -50 || true
          echo "=== Connector server log ==="
          cat "$ROOT_DIR/connector-server.log" | tail -50 || true

          # Check if servers are running
          SERVERS_READY=false
          for port in 3000 3003; do
            echo "Checking port $port..."
            for i in {1..30}; do
              if curl -s "http://localhost:$port" > /dev/null 2>&1; then
                echo "Server on port $port is ready"
                break
              fi
              echo "Waiting for port $port... (attempt $i)"
              sleep 2
            done
            # Verify the port is actually responding
            if curl -s "http://localhost:$port" > /dev/null 2>&1; then
              SERVERS_READY=true
            else
              echo "WARNING: Port $port is not responding!"
            fi
          done

          # Test if we can actually reach the site
          echo "Testing site access..."
          curl -v "http://localhost:3000/commerce/testing/" 2>&1 | head -50 || true

          # Create output directory
          mkdir -p "$ROOT_DIR/_site"
          cd "$ROOT_DIR/_site"

          # Generate list of all page URLs from markdown files
          cd "$ROOT_DIR/content"
          find src/pages -name "*.md" | sed 's|src/pages/||' | sed 's|\.md$||' | sed 's|/index$|/|' | while read path; do
            echo "http://localhost:3000/commerce/testing/$path"
          done > "$ROOT_DIR/urls.txt"

          echo "Generated $(wc -l < "$ROOT_DIR/urls.txt") URLs to crawl"
          cat "$ROOT_DIR/urls.txt"

          cd "$ROOT_DIR/_site"

          # Use wget to crawl and generate static site
          echo "Starting wget crawl..."
          wget \
            --input-file="$ROOT_DIR/urls.txt" \
            --page-requisites \
            --adjust-extension \
            --convert-links \
            --restrict-file-names=windows \
            --domains localhost \
            --execute robots=off \
            --wait=0.1 \
            --tries=3 \
            --timeout=30 \
            --verbose \
            2>&1 | tee "$ROOT_DIR/wget.log" || true

          echo "=== wget log tail ==="
          tail -100 "$ROOT_DIR/wget.log"

          # Copy all hlx_statics from adp-devsite source directly
          # This ensures all dynamically loaded blocks/components are available
          echo "Copying hlx_statics from adp-devsite source..."
          mkdir -p localhost+3000/hlx_statics
          cp -r "$ROOT_DIR/adp-devsite/hlx_statics/"* localhost+3000/hlx_statics/ 2>/dev/null || true
          
          echo "hlx_statics files copied:"
          find localhost+3000/hlx_statics -type f 2>/dev/null | wc -l
          echo "files"

          # Fetch API endpoints needed for dynamic content
          echo "Fetching API endpoints..."
          mkdir -p localhost+3000/commerce/testing
          mkdir -p localhost+3000/franklin_assets
          
          # Config endpoint (for side navigation/TOC)
          curl -s "http://localhost:3000/commerce/testing/config" -o localhost+3000/commerce/testing/config || true
          echo "Config endpoint saved"
          
          # Footer HTML
          curl -s "http://localhost:3000/franklin_assets/footer.plain.html" -o localhost+3000/franklin_assets/footer.plain.html || true
          echo "Footer HTML saved"
          
          # Product index map
          curl -s "http://localhost:3000/franklin_assets/product-index-map.json" -o localhost+3000/franklin_assets/product-index-map.json || true
          echo "Product index map saved"
          
          # Site-wide banner config
          curl -s "http://localhost:3000/commerce/testing/site-wide-banner.json" -o localhost+3000/commerce/testing/site-wide-banner.json || true
          echo "Site-wide banner config saved"

          # Debug: List what was downloaded
          echo "=== Downloaded files ==="
          find . -type f | head -50
          echo "Total files: $(find . -type f | wc -l)"

          # Organize the output structure
          # Note: --restrict-file-names=windows converts : to + in directory names
          if [ -d "localhost+3000" ]; then
            echo "Found localhost+3000 directory, organizing..."
            mv localhost+3000/* . 2>/dev/null || true
            rm -rf localhost+3000
          elif [ -d "localhost:3000" ]; then
            echo "Found localhost:3000 directory, organizing..."
            mv localhost:3000/* . 2>/dev/null || true
            rm -rf localhost:3000
          else
            echo "WARNING: No localhost directory found!"
            ls -la
          fi

          # Fix absolute paths for GitHub Pages
          # GitHub Pages serves at /commerce-testing/ but JS requests go to domain root
          # Solution: Inject INLINE interceptor script (must run before any other scripts)
          echo "Adding INLINE fetch interceptor for GitHub Pages compatibility..."
          
          # Create interceptor file that handles:
          # 1. fetch() - String URLs, Request objects, URL objects
          # 2. XMLHttpRequest
          # 3. Dynamically created DOM elements (img src, use href, link href, script src)
          # Uses MutationObserver to fix elements as they are added to the DOM
          printf '%s' '<script>!function(){var B="/commerce-testing";function fix(u){if(!u||typeof u!=="string")return null;if(u.startsWith("/")&&!u.startsWith(B)&&(u.startsWith("/hlx_statics")||u.startsWith("/franklin_assets")||u.startsWith("/commerce")))return B+u;return null}var F=window.fetch;window.fetch=function(u,o){var n;if(typeof u==="string"){n=fix(u);if(n)u=n}else if(u instanceof Request){n=fix(u.url);if(n)u=new Request(n,u)}return F.call(this,u,o)};var X=XMLHttpRequest.prototype.open;XMLHttpRequest.prototype.open=function(m,u){var n=fix(u);if(n)u=n;return X.apply(this,[m,u].concat([].slice.call(arguments,2)))};function fixEl(el){if(!el||!el.getAttribute)return;["src","href","xlink:href"].forEach(function(a){var v=el.getAttribute(a);var n=fix(v);if(n)el.setAttribute(a,n)});if(el.querySelectorAll){el.querySelectorAll("[src],[href]").forEach(fixEl)}}new MutationObserver(function(m){m.forEach(function(r){r.addedNodes.forEach(function(n){if(n.nodeType===1)fixEl(n)})})}).observe(document.documentElement,{childList:true,subtree:true});document.addEventListener("DOMContentLoaded",function(){fixEl(document.body)})}();</script>' > /tmp/interceptor.txt
          echo "Interceptor content:"
          cat /tmp/interceptor.txt
          
          # Use perl for injection (handles special chars correctly)
          find . -name "*.html" -type f | while read htmlfile; do
            perl -i -pe 'BEGIN{open(F,"/tmp/interceptor.txt");$s=<F>;chomp $s;close F} s/<head>/<head>$s/' "$htmlfile" 2>/dev/null || true
          done
          
          # Count modified files
          MODIFIED=$(grep -l 'commerce-testing.*fetch' commerce/testing/*.html 2>/dev/null | wc -l || echo "0")
          echo "Interceptor injection check: $MODIFIED files modified"
          
          # Debug: show first lines of a sample file
          echo "Sample HTML head (first 600 chars):"
          head -c 600 commerce/testing/index.html 2>/dev/null || head -c 600 commerce/testing/guide/index.html 2>/dev/null || echo "Could not read sample file"

          # Always create at least a minimal index.html
          echo '<!DOCTYPE html><html><head><meta charset="utf-8"><title>Commerce Testing - Preview</title><meta http-equiv="refresh" content="0; url=commerce/testing/"><link rel="canonical" href="commerce/testing/"></head><body><p>Redirecting to <a href="commerce/testing/">Commerce Testing documentation</a>...</p></body></html>' > index.html

          # If no commerce directory exists, create a fallback page
          if [ ! -d "commerce" ]; then
            echo "WARNING: No content was generated. Creating fallback page."
            mkdir -p commerce/testing
            echo '<!DOCTYPE html><html><head><meta charset="utf-8"><title>Commerce Testing - Build Failed</title><style>body{font-family:system-ui;max-width:800px;margin:50px auto;padding:20px}</style></head><body><h1>Preview Build Issue</h1><p>The static site generation encountered an issue. The development servers may not have started correctly.</p><p>Please check the <a href="https://github.com/AdobeDocs/commerce-testing/actions">GitHub Actions logs</a> for details.</p></body></html>' > commerce/testing/index.html
          fi

          # Stop servers
          kill $CONTENT_PID $DEVSITE_PID $CONNECTOR_PID 2>/dev/null || true

          echo "=== Final _site contents ==="
          find . -type f | wc -l
          echo "files in _site"
          ls -la

      - name: Setup Pages
        uses: actions/configure-pages@v5

      - name: Upload artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: _site

  deploy:
    name: Deploy
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    runs-on: ubuntu-latest
    needs: build
    outputs:
      page_url: ${{ steps.deployment.outputs.page_url }}
    steps:
      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4

